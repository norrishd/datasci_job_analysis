{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Top Terms by Job Type\n",
    "*David Norrish, October 2019*\n",
    "\n",
    "Using the trained phrase models, we can now compare different job types (data science vs data engineering vs control jobs) and see which phrases are most uplifted in each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "import spacy\n",
    "\n",
    "from utils import nlp, PARAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in all jobs CSVs, load bigram and trigram models and derive normed and phrased texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Normalise and phrase model texts\n",
    "Read in the job description files for data science, data engineering and control jobs. Normalise the text then fit the trigram model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data_engineer', 'control', 'data_scientist'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put DataFrames in a dictionary\n",
    "dfs = {str(path.stem[:-5]): pd.read_csv(path) for path in PARAMS['JOB_PATHS']}\n",
    "dfs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_model = Phraser(Phrases.load(str(PARAMS['BIGRAM_MODEL_PATH'])))\n",
    "trigram_model = Phraser(Phrases.load(str(PARAMS['TRIGRAM_MODEL_PATH'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps in the text cleaning:\n",
    "\n",
    "1. Start with full job description text\n",
    "2. Convert to spaCy-parsed doc\n",
    "3. Lemmatize to list of spacy.Token lower-case lemmas (with punctuation marks retained)\n",
    "  4. Save as space-separated string of tokens\n",
    "5. Apply phrase model to get list of string terms/phrases\n",
    "6. Drop punctuation tokens\n",
    "  - Currently done by joining phrase tokens into space-separated string and re-spaCy-parsing. Seems fairly inefficient, could probably just check for punctuation tokens, but non-trivial not to addidentally exclude valid tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_normed_text(df: DataFrame, col: str):\n",
    "    \"\"\"Normalize text by lematizing\"\"\"\n",
    "    normed_texts = []\n",
    "    for doc in nlp.pipe(df[col]):\n",
    "        cleaned_toks = [tok.lemma_.lower() for tok in doc if not tok.is_space]\n",
    "        normed_texts.append(' '.join(cleaned_toks))\n",
    "    df['normed_text'] = normed_texts\n",
    "    return df\n",
    "\n",
    "def add_phrased_text(df: DataFrame, col: str):\n",
    "    \"\"\"\n",
    "    Apply phrase model to join frequently co-occurring tokens.\n",
    "\n",
    "    Carry out in 2 passes: First retain all punctuation to fit phrase model the\n",
    "    same as was trained. In a second pass drop punctuation, as just want\n",
    "    term counts not punctuation.\n",
    "    \"\"\"\n",
    "    phrased_texts = []\n",
    "    for text in df[col]:\n",
    "        cleaned_toks = text.split(' ')\n",
    "        phrased_texts.append(' '.join(trigram_model[bigram_model[cleaned_toks]]))\n",
    "    cleaned_phrased = []\n",
    "    for doc in nlp.pipe(phrased_texts):\n",
    "        cleaned_phrased.append(' '.join([tok.text for tok in doc if not tok.is_punct]))\n",
    "    df['phrased_text'] = cleaned_phrased\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning data_engineer jobs...\n",
      "Cleaning control jobs...\n",
      "Cleaning data_scientist jobs...\n"
     ]
    }
   ],
   "source": [
    "for path, df in dfs.items():\n",
    "    print(f\"Cleaning {path} jobs...\")\n",
    "    df = add_normed_text(df, 'text')\n",
    "    df = add_phrased_text(df, 'normed_text')\n",
    "    output_path = PARAMS['CLEANED_PATH'] / f\"{path}_cleaned.csv\"\n",
    "    df.to_csv(output_path, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>institution</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>required skills</th>\n",
       "      <th>applicants skills</th>\n",
       "      <th>normed_text</th>\n",
       "      <th>phrased_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>GHD</td>\n",
       "      <td>27/09/2019</td>\n",
       "      <td>GHD Digital is rapidly growing &amp; are looking for that special person who can help drive the deli...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ghd digital be rapidly grow &amp; be look for that special person who can help drive the delivery of...</td>\n",
       "      <td>ghd_digital be rapidly grow be_look_for that special person who_can help drive the delivery of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>fibreHR</td>\n",
       "      <td>30/09/2019</td>\n",
       "      <td>Bring your love of data science to this role\\n    Exciting time of growth\\n    Collaborative...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bring -pron- love of datum science to this role exciting time of growth collaborative and suppor...</td>\n",
       "      <td>bring -pron- love of datum_science to this_role exciting time of growth collaborative and suppor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mane Consulting</td>\n",
       "      <td>28/09/2019</td>\n",
       "      <td>Highly regarded, Global specilaist Data and Analytics solutions company seeks a Data Scientist p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>highly regard , global specilaist data and analytics solution company seek a data scientist pass...</td>\n",
       "      <td>highly_regard global specilaist data and analytics solution company seek a data_scientist passio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Capgemini</td>\n",
       "      <td>14/09/2019</td>\n",
       "      <td>A global leader in consulting, technology services and digital transformation, the Capgemini Gro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Python (Programming Language), Machine Learning, SQL, Data Analysis, R, Data Science, Microsoft ...</td>\n",
       "      <td>a global leader in consulting , technology service and digital transformation , the capgemini gr...</td>\n",
       "      <td>a global leader in consulting technology service and digital_transformation the capgemini group ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>Data Scientist - State Government</td>\n",
       "      <td>Hudson</td>\n",
       "      <td>30/09/2019</td>\n",
       "      <td>Data Scientist - 9 months contract role\\n\\n    9 month contract role within a key state Gov\\n   ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>data scientist - 9 month contract role 9 month contract role within a key state gov child inform...</td>\n",
       "      <td>data_scientist 9 month_contract role 9 month_contract role within a key state gov child informat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                title      institution        date  \\\n",
       "6                      Data Scientist              GHD  27/09/2019   \n",
       "36                     Data Scientist          fibreHR  30/09/2019   \n",
       "24                     Data Scientist  Mane Consulting  28/09/2019   \n",
       "31                     Data Scientist        Capgemini  14/09/2019   \n",
       "37  Data Scientist - State Government           Hudson  30/09/2019   \n",
       "\n",
       "                                                                                                   text  \\\n",
       "6   GHD Digital is rapidly growing & are looking for that special person who can help drive the deli...   \n",
       "36      Bring your love of data science to this role\\n    Exciting time of growth\\n    Collaborative...   \n",
       "24  Highly regarded, Global specilaist Data and Analytics solutions company seeks a Data Scientist p...   \n",
       "31  A global leader in consulting, technology services and digital transformation, the Capgemini Gro...   \n",
       "37  Data Scientist - 9 months contract role\\n\\n    9 month contract role within a key state Gov\\n   ...   \n",
       "\n",
       "   required skills  \\\n",
       "6              NaN   \n",
       "36             NaN   \n",
       "24             NaN   \n",
       "31             NaN   \n",
       "37             NaN   \n",
       "\n",
       "                                                                                      applicants skills  \\\n",
       "6                                                                                                   NaN   \n",
       "36                                                                                                  NaN   \n",
       "24                                                                                                  NaN   \n",
       "31  Python (Programming Language), Machine Learning, SQL, Data Analysis, R, Data Science, Microsoft ...   \n",
       "37                                                                                                  NaN   \n",
       "\n",
       "                                                                                            normed_text  \\\n",
       "6   ghd digital be rapidly grow & be look for that special person who can help drive the delivery of...   \n",
       "36  bring -pron- love of datum science to this role exciting time of growth collaborative and suppor...   \n",
       "24  highly regard , global specilaist data and analytics solution company seek a data scientist pass...   \n",
       "31  a global leader in consulting , technology service and digital transformation , the capgemini gr...   \n",
       "37  data scientist - 9 month contract role 9 month contract role within a key state gov child inform...   \n",
       "\n",
       "                                                                                           phrased_text  \n",
       "6   ghd_digital be rapidly grow be_look_for that special person who_can help drive the delivery of t...  \n",
       "36  bring -pron- love of datum_science to this_role exciting time of growth collaborative and suppor...  \n",
       "24  highly_regard global specilaist data and analytics solution company seek a data_scientist passio...  \n",
       "31  a global leader in consulting technology service and digital_transformation the capgemini group ...  \n",
       "37  data_scientist 9 month_contract role 9 month_contract role within a key state gov child informat...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['data_scientist'].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect an example of the original, normalized and phrase-modelled text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Opportunity\n",
      "\n",
      "We're looking for an experienced practitioner with a track record in building and delivering practical Machine Learning driven products at scale. You will join an established Machine Learning / Data Science capability driving the glo\n",
      "\n",
      "==================================================\n",
      "the opportunity -pron- be look for an experienced practitioner with a track record in build and deliver practical machine learning drive product at scale . -pron- will join an established machine learning / data science capability drive the global se\n",
      "\n",
      "==================================================\n",
      "the opportunity -pron- be_look_for an_experienced practitioner with a track_record in build and deliver practical machine_learning drive product at_scale -pron- will join an established machine_learning data_science capability drive the global seek a\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "for col in ['text', 'normed_text', 'phrased_text']:\n",
    "    print(dfs['data_scientist'].iloc[5][col][:250] + '\\n')\n",
    "    print('=' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get document frequency & lift\n",
    "We'll now compute the % of jobs in each job class that each term appears in.\n",
    "\n",
    "To ensure the same vocabulary appears across all job types, we'll first concatenate the dataframes together to derive the vocabulary from the full corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column noting which type of job every job comes from before concatenating\n",
    "for key, df in dfs.items():\n",
    "    df['job_type'] = key\n",
    "\n",
    "full_df = pd.concat(dfs.values(), sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate count vectorizer. Have already lowercased and fit phrase model, so can just use \"unigrams\". Can also drop stopwords here. Note that we tokenize on a single space, as the default tokenizer also splits on punctuation, meaning that phrases like \"3_+\\_year\" get broken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job descriptions: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(182, 2237)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(\n",
    "    lowercase=False,\n",
    "    tokenizer=lambda x: x.split(' '),\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 1),\n",
    "    min_df=3\n",
    ")\n",
    "\n",
    "term_counts = vectorizer.fit_transform(full_df['phrased_text'])\n",
    "print(\"Job descriptions: \")\n",
    "term_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or can use the scikit n-grams instead of phrase model. Gives similar results, with ordering a little shifted and some pros and cons. The main difference is it double counts subsets of larger N-grams, which is good and bad. E.g. 'Python' gets a very high score under the scikit method as every instance is counted, weheras Gensim learns two phrases including it: \"python_r\" and \"r_python\" so it can only get counted once in each of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = CountVectorizer(\n",
    "#     lowercase=False,\n",
    "#     stop_words='english',\n",
    "#     ngram_range=(1, 3),\n",
    "#     min_df=3\n",
    "# )\n",
    "\n",
    "# term_counts = vectorizer.fit_transform(full_df['normed_text'])\n",
    "# term_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put it into a term frequency DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$</th>\n",
       "      <th>'s</th>\n",
       "      <th>+</th>\n",
       "      <th>+61</th>\n",
       "      <th>-_edge</th>\n",
       "      <th>-_making</th>\n",
       "      <th>-_minded</th>\n",
       "      <th>-_orient</th>\n",
       "      <th>-_term</th>\n",
       "      <th>/_life_balance</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>08</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>10,000</th>\n",
       "      <th>100</th>\n",
       "      <th>10_year</th>\n",
       "      <th>12</th>\n",
       "      <th>12_month</th>\n",
       "      <th>13</th>\n",
       "      <th>15</th>\n",
       "      <th>2</th>\n",
       "      <th>2012</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>24</th>\n",
       "      <th>2_year</th>\n",
       "      <th>3</th>\n",
       "      <th>30</th>\n",
       "      <th>3_+_year</th>\n",
       "      <th>3_year</th>\n",
       "      <th>4</th>\n",
       "      <th>40</th>\n",
       "      <th>4_+_year</th>\n",
       "      <th>5</th>\n",
       "      <th>50</th>\n",
       "      <th>5_+_year</th>\n",
       "      <th>5_year</th>\n",
       "      <th>6</th>\n",
       "      <th>6_month</th>\n",
       "      <th>7</th>\n",
       "      <th>70</th>\n",
       "      <th>7370</th>\n",
       "      <th>8</th>\n",
       "      <th>8637</th>\n",
       "      <th>9</th>\n",
       "      <th>a_/_b</th>\n",
       "      <th>a_difference</th>\n",
       "      <th>a_few</th>\n",
       "      <th>a_range_of</th>\n",
       "      <th>a_variety_of</th>\n",
       "      <th>a_wide_range</th>\n",
       "      <th>ability</th>\n",
       "      <th>ability_to</th>\n",
       "      <th>able_to</th>\n",
       "      <th>aboriginal</th>\n",
       "      <th>about_us</th>\n",
       "      <th>academic</th>\n",
       "      <th>accelerate</th>\n",
       "      <th>accept</th>\n",
       "      <th>access</th>\n",
       "      <th>accessibility</th>\n",
       "      <th>accessible</th>\n",
       "      <th>accomplish</th>\n",
       "      <th>accord</th>\n",
       "      <th>accordance</th>\n",
       "      <th>account</th>\n",
       "      <th>accountability</th>\n",
       "      <th>accountable</th>\n",
       "      <th>accounting</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accurate</th>\n",
       "      <th>accurately</th>\n",
       "      <th>achieve</th>\n",
       "      <th>acquire</th>\n",
       "      <th>acquisition</th>\n",
       "      <th>across_a_range</th>\n",
       "      <th>across_multiple</th>\n",
       "      <th>act</th>\n",
       "      <th>act_as</th>\n",
       "      <th>action</th>\n",
       "      <th>actionable</th>\n",
       "      <th>actionable_insight</th>\n",
       "      <th>active</th>\n",
       "      <th>actively</th>\n",
       "      <th>activity</th>\n",
       "      <th>actuarial</th>\n",
       "      <th>ad</th>\n",
       "      <th>ad_-_hoc</th>\n",
       "      <th>adapt</th>\n",
       "      <th>add</th>\n",
       "      <th>add_value</th>\n",
       "      <th>additional</th>\n",
       "      <th>address</th>\n",
       "      <th>adept</th>\n",
       "      <th>administration</th>\n",
       "      <th>adobe</th>\n",
       "      <th>...</th>\n",
       "      <th>use</th>\n",
       "      <th>useful</th>\n",
       "      <th>user</th>\n",
       "      <th>utilise</th>\n",
       "      <th>utility</th>\n",
       "      <th>utilize</th>\n",
       "      <th>ux</th>\n",
       "      <th>vacancy</th>\n",
       "      <th>valid</th>\n",
       "      <th>validate</th>\n",
       "      <th>validation</th>\n",
       "      <th>valuable</th>\n",
       "      <th>value</th>\n",
       "      <th>varied</th>\n",
       "      <th>variety_of</th>\n",
       "      <th>various</th>\n",
       "      <th>vary</th>\n",
       "      <th>vast</th>\n",
       "      <th>vendor</th>\n",
       "      <th>verbal</th>\n",
       "      <th>verbal_communication_skill</th>\n",
       "      <th>verify</th>\n",
       "      <th>version</th>\n",
       "      <th>vertical</th>\n",
       "      <th>very_strong</th>\n",
       "      <th>veteran</th>\n",
       "      <th>vibrant</th>\n",
       "      <th>victoria</th>\n",
       "      <th>victorian</th>\n",
       "      <th>video</th>\n",
       "      <th>view</th>\n",
       "      <th>visa</th>\n",
       "      <th>vision</th>\n",
       "      <th>visit</th>\n",
       "      <th>visual</th>\n",
       "      <th>visualisation</th>\n",
       "      <th>visualisation_tool</th>\n",
       "      <th>visualise</th>\n",
       "      <th>visualization</th>\n",
       "      <th>visualization_tool</th>\n",
       "      <th>vital</th>\n",
       "      <th>voice</th>\n",
       "      <th>volume</th>\n",
       "      <th>volunteer</th>\n",
       "      <th>want</th>\n",
       "      <th>warehouse</th>\n",
       "      <th>warehousing</th>\n",
       "      <th>water</th>\n",
       "      <th>way</th>\n",
       "      <th>web</th>\n",
       "      <th>website</th>\n",
       "      <th>week</th>\n",
       "      <th>weekly</th>\n",
       "      <th>welcome</th>\n",
       "      <th>wellbeing</th>\n",
       "      <th>wellness</th>\n",
       "      <th>west</th>\n",
       "      <th>whilst</th>\n",
       "      <th>who_can</th>\n",
       "      <th>who_enjoy</th>\n",
       "      <th>who_want</th>\n",
       "      <th>wide</th>\n",
       "      <th>wide_variety</th>\n",
       "      <th>will_also</th>\n",
       "      <th>will_be_responsible</th>\n",
       "      <th>willing</th>\n",
       "      <th>willingness</th>\n",
       "      <th>win</th>\n",
       "      <th>windows</th>\n",
       "      <th>woman</th>\n",
       "      <th>word</th>\n",
       "      <th>work</th>\n",
       "      <th>work180</th>\n",
       "      <th>work_alongside</th>\n",
       "      <th>work_closely_with</th>\n",
       "      <th>work_collaboratively</th>\n",
       "      <th>work_with</th>\n",
       "      <th>workflow</th>\n",
       "      <th>workforce</th>\n",
       "      <th>working</th>\n",
       "      <th>working_environment</th>\n",
       "      <th>working_right</th>\n",
       "      <th>workload</th>\n",
       "      <th>workplace</th>\n",
       "      <th>workshop</th>\n",
       "      <th>world</th>\n",
       "      <th>worldwide</th>\n",
       "      <th>would_be</th>\n",
       "      <th>would_love</th>\n",
       "      <th>write</th>\n",
       "      <th>write_communication_skill</th>\n",
       "      <th>writing</th>\n",
       "      <th>written</th>\n",
       "      <th>xgboost</th>\n",
       "      <th>xml</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>young</th>\n",
       "      <th>|</th>\n",
       "      <th>â€™s</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>data_engineer</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>data_engineer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>data_engineer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>data_engineer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>data_engineer</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2236 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               $  's  +  +61  -_edge  -_making  -_minded  -_orient  -_term  \\\n",
       "job_type                                                                     \n",
       "data_engineer  1   1  0    0       0         0         0         0       0   \n",
       "data_engineer  0   0  0    0       0         0         0         0       0   \n",
       "data_engineer  0   0  0    0       0         0         0         0       0   \n",
       "data_engineer  0   0  0    1       0         0         0         0       0   \n",
       "data_engineer  0   1  0    0       0         0         0         0       0   \n",
       "\n",
       "               /_life_balance  02  03  08  1  10  10,000  100  10_year  12  \\\n",
       "job_type                                                                     \n",
       "data_engineer               0   0   0   0  0   0       0    0        0   0   \n",
       "data_engineer               0   0   0   0  0   0       0    0        0   0   \n",
       "data_engineer               0   0   1   0  0   0       0    0        0   0   \n",
       "data_engineer               0   0   0   0  0   0       0    0        0   0   \n",
       "data_engineer               0   0   0   0  0   0       0    0        0   0   \n",
       "\n",
       "               12_month  13  15  2  2012  2017  2018  2019  2020  24  2_year  \\\n",
       "job_type                                                                       \n",
       "data_engineer         1   0   0  0     0     0     0     0     0   0       0   \n",
       "data_engineer         0   0   0  0     0     0     0     0     0   0       0   \n",
       "data_engineer         0   0   0  0     0     0     0     0     0   0       0   \n",
       "data_engineer         0   0   0  0     0     0     0     1     0   0       1   \n",
       "data_engineer         0   0   0  0     0     0     0     0     0   0       0   \n",
       "\n",
       "               3  30  3_+_year  3_year  4  40  4_+_year  5  50  5_+_year  \\\n",
       "job_type                                                                   \n",
       "data_engineer  0   1         0       0  0   0         0  0   0         0   \n",
       "data_engineer  0   0         0       0  0   0         0  0   0         0   \n",
       "data_engineer  0   0         0       0  0   0         0  0   0         0   \n",
       "data_engineer  0   0         0       0  0   0         0  0   0         0   \n",
       "data_engineer  0   0         0       0  0   0         0  0   0         0   \n",
       "\n",
       "               5_year  6  6_month  7  70  7370  8  8637  9  a_/_b  \\\n",
       "job_type                                                            \n",
       "data_engineer       0  1        0  1   0     0  0     0  0      0   \n",
       "data_engineer       0  0        0  0   0     0  0     0  0      0   \n",
       "data_engineer       0  0        0  0   0     0  0     0  0      0   \n",
       "data_engineer       0  0        0  0   0     0  0     0  0      0   \n",
       "data_engineer       1  0        0  0   0     0  0     0  0      0   \n",
       "\n",
       "               a_difference  a_few  a_range_of  a_variety_of  a_wide_range  \\\n",
       "job_type                                                                     \n",
       "data_engineer             0      0           0             0             0   \n",
       "data_engineer             0      0           2             0             0   \n",
       "data_engineer             0      0           1             0             0   \n",
       "data_engineer             0      0           0             0             0   \n",
       "data_engineer             1      0           0             0             0   \n",
       "\n",
       "               ability  ability_to  able_to  aboriginal  about_us  academic  \\\n",
       "job_type                                                                      \n",
       "data_engineer        0           2        0           0         0         0   \n",
       "data_engineer        0           0        0           0         0         0   \n",
       "data_engineer        0           1        0           0         0         0   \n",
       "data_engineer        1           0        0           1         0         0   \n",
       "data_engineer        0           0        0           0         0         0   \n",
       "\n",
       "               accelerate  accept  access  accessibility  accessible  \\\n",
       "job_type                                                               \n",
       "data_engineer           0       0       3              0           0   \n",
       "data_engineer           0       0       0              0           2   \n",
       "data_engineer           0       0       0              0           0   \n",
       "data_engineer           0       0       2              0           0   \n",
       "data_engineer           0       0       0              0           0   \n",
       "\n",
       "               accomplish  accord  accordance  account  accountability  \\\n",
       "job_type                                                                 \n",
       "data_engineer           0       0           0        0               0   \n",
       "data_engineer           0       0           0        0               0   \n",
       "data_engineer           0       0           0        0               0   \n",
       "data_engineer           0       0           0        0               0   \n",
       "data_engineer           0       0           0        0               0   \n",
       "\n",
       "               accountable  accounting  accuracy  accurate  accurately  \\\n",
       "job_type                                                                 \n",
       "data_engineer            0           0         0         0           0   \n",
       "data_engineer            0           0         0         0           0   \n",
       "data_engineer            0           0         0         0           0   \n",
       "data_engineer            0           0         0         0           0   \n",
       "data_engineer            0           0         0         0           0   \n",
       "\n",
       "               achieve  acquire  acquisition  across_a_range  across_multiple  \\\n",
       "job_type                                                                        \n",
       "data_engineer        0        0            0               0                0   \n",
       "data_engineer        0        2            0               0                0   \n",
       "data_engineer        0        0            0               0                0   \n",
       "data_engineer        0        0            0               0                1   \n",
       "data_engineer        0        0            0               0                0   \n",
       "\n",
       "               act  act_as  action  actionable  actionable_insight  active  \\\n",
       "job_type                                                                     \n",
       "data_engineer    1       0       0           0                   0       1   \n",
       "data_engineer    0       0       0           0                   0       0   \n",
       "data_engineer    0       0       0           0                   0       0   \n",
       "data_engineer    0       0       0           0                   0       0   \n",
       "data_engineer    0       0       0           0                   0       0   \n",
       "\n",
       "               actively  activity  actuarial  ad  ad_-_hoc  adapt  add  \\\n",
       "job_type                                                                 \n",
       "data_engineer         0         1          0   0         0      0    0   \n",
       "data_engineer         1         0          0   0         0      0    0   \n",
       "data_engineer         0         0          0   0         0      0    0   \n",
       "data_engineer         0         0          0   0         0      0    0   \n",
       "data_engineer         0         0          0   0         0      0    0   \n",
       "\n",
       "               add_value  additional  address  adept  administration  adobe  \\\n",
       "job_type                                                                      \n",
       "data_engineer          0           0        0      0               0      0   \n",
       "data_engineer          0           0        0      0               0      0   \n",
       "data_engineer          0           0        0      0               0      0   \n",
       "data_engineer          1           0        1      0               0      0   \n",
       "data_engineer          0           0        0      0               0      0   \n",
       "\n",
       "               ...  use  useful  user  utilise  utility  utilize  ux  vacancy  \\\n",
       "job_type       ...                                                              \n",
       "data_engineer  ...    2       0     0        0        0        0   0        0   \n",
       "data_engineer  ...    1       0     0        0        0        0   0        0   \n",
       "data_engineer  ...    1       1     1        0        0        0   0        0   \n",
       "data_engineer  ...    1       0     0        0        0        0   0        0   \n",
       "data_engineer  ...    0       0     0        0        0        0   0        0   \n",
       "\n",
       "               valid  validate  validation  valuable  value  varied  \\\n",
       "job_type                                                              \n",
       "data_engineer      0         0           0         1      1       0   \n",
       "data_engineer      0         0           0         0      2       0   \n",
       "data_engineer      0         0           0         0      0       0   \n",
       "data_engineer      0         0           0         0      1       0   \n",
       "data_engineer      0         0           0         0      0       0   \n",
       "\n",
       "               variety_of  various  vary  vast  vendor  verbal  \\\n",
       "job_type                                                         \n",
       "data_engineer           0        0     0     0       0       2   \n",
       "data_engineer           0        1     0     0       0       0   \n",
       "data_engineer           0        0     0     0       0       0   \n",
       "data_engineer           1        1     0     1       0       0   \n",
       "data_engineer           0        0     0     0       0       0   \n",
       "\n",
       "               verbal_communication_skill  verify  version  vertical  \\\n",
       "job_type                                                               \n",
       "data_engineer                           0       0        0         0   \n",
       "data_engineer                           0       0        0         0   \n",
       "data_engineer                           0       0        0         0   \n",
       "data_engineer                           0       0        0         0   \n",
       "data_engineer                           0       0        0         0   \n",
       "\n",
       "               very_strong  veteran  vibrant  victoria  victorian  video  \\\n",
       "job_type                                                                   \n",
       "data_engineer            0        0        0         0          0      1   \n",
       "data_engineer            0        0        0         0          0      0   \n",
       "data_engineer            1        0        0         0          0      0   \n",
       "data_engineer            0        0        0         0          0      0   \n",
       "data_engineer            0        0        0         0          0      0   \n",
       "\n",
       "               view  visa  vision  visit  visual  visualisation  \\\n",
       "job_type                                                          \n",
       "data_engineer     0     2       0      0       0              0   \n",
       "data_engineer     0     0       0      1       0              0   \n",
       "data_engineer     0     0       0      0       0              0   \n",
       "data_engineer     0     0       0      0       0              0   \n",
       "data_engineer     0     0       0      0       0              0   \n",
       "\n",
       "               visualisation_tool  visualise  visualization  \\\n",
       "job_type                                                      \n",
       "data_engineer                   0          0              0   \n",
       "data_engineer                   1          0              0   \n",
       "data_engineer                   0          0              0   \n",
       "data_engineer                   0          0              0   \n",
       "data_engineer                   0          0              0   \n",
       "\n",
       "               visualization_tool  vital  voice  volume  volunteer  want  \\\n",
       "job_type                                                                   \n",
       "data_engineer                   0      0      0       0          0     0   \n",
       "data_engineer                   0      1      0       0          0     2   \n",
       "data_engineer                   0      0      0       0          0     1   \n",
       "data_engineer                   0      0      0       0          0     0   \n",
       "data_engineer                   0      0      0       0          0     0   \n",
       "\n",
       "               warehouse  warehousing  water  way  web  website  week  weekly  \\\n",
       "job_type                                                                        \n",
       "data_engineer          0            0      0    1    0        0     1       2   \n",
       "data_engineer          1            0      0    0    0        1     0       0   \n",
       "data_engineer          0            0      0    0    0        0     0       0   \n",
       "data_engineer          0            1      0    1    0        0     0       0   \n",
       "data_engineer          0            0      0    1    0        0     0       0   \n",
       "\n",
       "               welcome  wellbeing  wellness  west  whilst  who_can  who_enjoy  \\\n",
       "job_type                                                                        \n",
       "data_engineer        0          0         0     0       0        0          0   \n",
       "data_engineer        0          0         0     0       0        0          0   \n",
       "data_engineer        0          0         0     0       0        0          1   \n",
       "data_engineer        0          1         0     0       0        0          0   \n",
       "data_engineer        0          0         0     0       0        0          0   \n",
       "\n",
       "               who_want  wide  wide_variety  will_also  will_be_responsible  \\\n",
       "job_type                                                                      \n",
       "data_engineer         0     0             0          1                    0   \n",
       "data_engineer         0     0             0          1                    0   \n",
       "data_engineer         0     0             0          0                    0   \n",
       "data_engineer         0     0             0          1                    0   \n",
       "data_engineer         0     0             0          0                    0   \n",
       "\n",
       "               willing  willingness  win  windows  woman  word  work  work180  \\\n",
       "job_type                                                                        \n",
       "data_engineer        0            1    0        1      0     0     7        0   \n",
       "data_engineer        0            0    0        0      0     0     8        0   \n",
       "data_engineer        0            0    0        0      0     0     1        0   \n",
       "data_engineer        0            0    0        0      0     0     4        0   \n",
       "data_engineer        0            0    0        0      0     0     1        0   \n",
       "\n",
       "               work_alongside  work_closely_with  work_collaboratively  \\\n",
       "job_type                                                                 \n",
       "data_engineer               0                  0                     0   \n",
       "data_engineer               0                  1                     1   \n",
       "data_engineer               0                  0                     0   \n",
       "data_engineer               0                  0                     0   \n",
       "data_engineer               0                  0                     0   \n",
       "\n",
       "               work_with  workflow  workforce  working  working_environment  \\\n",
       "job_type                                                                      \n",
       "data_engineer          0         0          0        0                    0   \n",
       "data_engineer          3         0          0        0                    0   \n",
       "data_engineer          0         0          0        0                    0   \n",
       "data_engineer          3         0          0        2                    0   \n",
       "data_engineer          0         0          0        0                    0   \n",
       "\n",
       "               working_right  workload  workplace  workshop  world  worldwide  \\\n",
       "job_type                                                                        \n",
       "data_engineer              0         0          0         0      1          0   \n",
       "data_engineer              0         0          0         0      3          0   \n",
       "data_engineer              0         0          0         0      0          0   \n",
       "data_engineer              0         0          0         0      1          0   \n",
       "data_engineer              0         0          0         0      0          0   \n",
       "\n",
       "               would_be  would_love  write  write_communication_skill  \\\n",
       "job_type                                                                \n",
       "data_engineer         0           0      1                          1   \n",
       "data_engineer         0           0      1                          0   \n",
       "data_engineer         0           0      0                          0   \n",
       "data_engineer         0           0      0                          0   \n",
       "data_engineer         0           0      0                          0   \n",
       "\n",
       "               writing  written  xgboost  xml  year  yes  young  |  â€™s  \n",
       "job_type                                                                \n",
       "data_engineer        0        0        0    1     1    0      0  0   1  \n",
       "data_engineer        0        0        0    0     0    0      0  0   3  \n",
       "data_engineer        0        0        0    0     0    0      0  0   0  \n",
       "data_engineer        0        0        0    0     0    0      1  0   1  \n",
       "data_engineer        0        0        0    0     0    0      0  6   1  \n",
       "\n",
       "[5 rows x 2236 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_freq_df = pd.DataFrame(\n",
    "    data=term_counts.toarray(),\n",
    "    columns=vectorizer.get_feature_names(),\n",
    "    index=full_df['job_type']\n",
    ").drop('-pron-', axis=1)\n",
    "\n",
    "term_freq_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Detour - combine similar phrases\n",
    "There are several phrases and terms that are very similar and which we should combine, e.g. \"statistic\" and \"statistics\".\n",
    "\n",
    "We can find these in a couple of manners:\n",
    "\n",
    "1. Levenshtein distance (edit distance)\n",
    "2. Vector cosine similarity\n",
    "\n",
    "We will investigate both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_terms = term_freq_df.sum().sort_values(ascending=False)\n",
    "# top_terms.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# import editdistance\n",
    "\n",
    "# distances = []\n",
    "\n",
    "# # Dynamic programming algorithm a little slow, so just consider top N terms\n",
    "# TOP_N = 400\n",
    "\n",
    "# for i in range(TOP_N):\n",
    "#     for j in range(i + 1, TOP_N):\n",
    "#         # Only compare words with same first letter;\n",
    "#         # Otherwise get a huge number of irrelevant candidates\n",
    "#         if top_terms.index[i][0] == top_terms.index[j][0]:\n",
    "#             doc1 = nlp(top_terms.index[i].replace('_', ' '))\n",
    "#             doc2 = nlp(top_terms.index[j].replace('_', ' '))\n",
    "#             distances.append((doc1.text, doc2.text, editdistance.eval(doc1.text, doc2.text)))\n",
    "\n",
    "# distance_df = pd.DataFrame(\n",
    "#     data=sorted(distances, key=lambda kv: kv[2]),\n",
    "#     columns=['term1', 'term2', 'distance']\n",
    "# )\n",
    "# # Number of irrelevant matches explodes beyond edit distance of 2\n",
    "# distance_df = distance_df[distance_df['distance'] < 3]\n",
    "# print(distance_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# similar_vecs = []\n",
    "\n",
    "# docs = list(nlp.pipe([term.replace('_', ' ') for term in top_terms.index[:1000]]))\n",
    "\n",
    "# for i in range(len(docs)):\n",
    "#     doc1 = docs[i]\n",
    "#     if doc1.vector_norm == 0:  # 0-vector for out-of-vocab terms\n",
    "#         continue\n",
    "#     for j in range(i + 1, len(docs)):\n",
    "#         doc2 = docs[j]\n",
    "#         if doc2.vector_norm == 0:\n",
    "#             continue\n",
    "#         else:\n",
    "#             similar_vecs.append((doc1.text, doc2.text, doc1.similarity(doc2)))\n",
    "\n",
    "# similarity_df = pd.DataFrame(\n",
    "#     data=sorted(similar_vecs, key=lambda kv: kv[2], reverse=True),\n",
    "#     columns=['term1', 'term2', 'similarity']\n",
    "# )\n",
    "# similarity_df = similarity_df[similarity_df['similarity'] > 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = {\n",
    "    'analytic': 'analytics',\n",
    "    'analysis': 'analytics',\n",
    "    'statistic': 'statistics',\n",
    "    'statistical': 'statistics',\n",
    "    'datum': 'data',\n",
    "    'big_datum': 'big_data',\n",
    "    'datum_science': 'data_science',\n",
    "    'optimization': 'optimisation',\n",
    "    'mentorship': 'mentoring',\n",
    "    'mathematic': 'mathematics',\n",
    "    'mathematical': 'mathematics',\n",
    "    'visualization': 'visualisation',\n",
    "    'machine_learning_technique': 'machine_learning',\n",
    "    'machine_learning_algorithm': 'machine_learning',\n",
    "    'machine_learn': 'machine_learning',\n",
    "    'modeling': 'modelling',\n",
    "    'predictive_model': 'predictive_modelling',\n",
    "    'ai': 'artificial_intelligence',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_terms(df, mapping, verbose=True):\n",
    "    \"\"\"For a given term frequency dataframe, merge terms according to a dictionary mapping\"\"\"\n",
    "    for term1, term2 in mapping.items():\n",
    "        if verbose:\n",
    "            print(f\"Map `{term1}` to `{term2}\")\n",
    "        df[term2] = df[term1] + df[term2]\n",
    "        df = df.drop(term1, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map `analytic` to `analytics\n",
      "Map `analysis` to `analytics\n",
      "Map `statistic` to `statistics\n",
      "Map `statistical` to `statistics\n",
      "Map `datum` to `data\n",
      "Map `big_datum` to `big_data\n",
      "Map `datum_science` to `data_science\n",
      "Map `optimization` to `optimisation\n",
      "Map `mentorship` to `mentoring\n",
      "Map `mathematic` to `mathematics\n",
      "Map `mathematical` to `mathematics\n",
      "Map `visualization` to `visualisation\n",
      "Map `machine_learning_technique` to `machine_learning\n",
      "Map `machine_learning_algorithm` to `machine_learning\n",
      "Map `machine_learn` to `machine_learning\n",
      "Map `modeling` to `modelling\n",
      "Map `predictive_model` to `predictive_modelling\n",
      "Map `ai` to `artificial_intelligence\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(182, 2218)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_freq_df = merge_terms(term_freq_df, mappings)\n",
    "term_freq_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Back to the cleaning\n",
    "\n",
    "Convert from term frequency to document probability - i.e. the percentage of documents containing each term per job category. To avoid 0-values, we apply Laplace smoothing by effectively adding an extra imaginary job description that contains each term for each job class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_term_probability(term_freqs_df, smoothing=1):\n",
    "    \"\"\"Derive document frequency for each term then convert to smoothed probability\"\"\"\n",
    "    # Binarise to yes/no for whether each term was in each document\n",
    "    doc_freq_df = term_freqs_df.applymap(lambda x: min(x, 1))\n",
    "\n",
    "    # Get smoothed probability for each job class\n",
    "    stats_df = doc_freq_df.groupby(doc_freq_df.index).apply(\n",
    "        lambda x: (x.sum() + 1) / (x.shape[0] + 1)\n",
    "    )\n",
    "\n",
    "    return stats_df\n",
    "\n",
    "def get_lift(term_prob_df, control_grp='control'):\n",
    "    \"\"\"Derive uplift for each term compared to some control\"\"\"\n",
    "    term_prob_df.index.name = 'term'\n",
    "    for category in term_prob_df.index.values:\n",
    "        if category != control_grp:\n",
    "            term_prob_df.loc[f'{category}_lift'] = term_prob_df.loc[category] / term_prob_df.loc[control_grp]\n",
    "\n",
    "    return term_prob_df.transpose().sort_values('control', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$</th>\n",
       "      <th>'s</th>\n",
       "      <th>+</th>\n",
       "      <th>+61</th>\n",
       "      <th>-_edge</th>\n",
       "      <th>-_making</th>\n",
       "      <th>-_minded</th>\n",
       "      <th>-_orient</th>\n",
       "      <th>-_term</th>\n",
       "      <th>/_life_balance</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>08</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>10,000</th>\n",
       "      <th>100</th>\n",
       "      <th>10_year</th>\n",
       "      <th>12</th>\n",
       "      <th>12_month</th>\n",
       "      <th>13</th>\n",
       "      <th>15</th>\n",
       "      <th>2</th>\n",
       "      <th>2012</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>24</th>\n",
       "      <th>2_year</th>\n",
       "      <th>3</th>\n",
       "      <th>30</th>\n",
       "      <th>3_+_year</th>\n",
       "      <th>3_year</th>\n",
       "      <th>4</th>\n",
       "      <th>40</th>\n",
       "      <th>4_+_year</th>\n",
       "      <th>5</th>\n",
       "      <th>50</th>\n",
       "      <th>5_+_year</th>\n",
       "      <th>5_year</th>\n",
       "      <th>6</th>\n",
       "      <th>6_month</th>\n",
       "      <th>7</th>\n",
       "      <th>70</th>\n",
       "      <th>7370</th>\n",
       "      <th>8</th>\n",
       "      <th>8637</th>\n",
       "      <th>9</th>\n",
       "      <th>a_/_b</th>\n",
       "      <th>a_difference</th>\n",
       "      <th>a_few</th>\n",
       "      <th>a_range_of</th>\n",
       "      <th>a_variety_of</th>\n",
       "      <th>a_wide_range</th>\n",
       "      <th>ability</th>\n",
       "      <th>ability_to</th>\n",
       "      <th>able_to</th>\n",
       "      <th>aboriginal</th>\n",
       "      <th>about_us</th>\n",
       "      <th>academic</th>\n",
       "      <th>accelerate</th>\n",
       "      <th>accept</th>\n",
       "      <th>access</th>\n",
       "      <th>accessibility</th>\n",
       "      <th>accessible</th>\n",
       "      <th>accomplish</th>\n",
       "      <th>accord</th>\n",
       "      <th>accordance</th>\n",
       "      <th>account</th>\n",
       "      <th>accountability</th>\n",
       "      <th>accountable</th>\n",
       "      <th>accounting</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accurate</th>\n",
       "      <th>accurately</th>\n",
       "      <th>achieve</th>\n",
       "      <th>acquire</th>\n",
       "      <th>acquisition</th>\n",
       "      <th>across_a_range</th>\n",
       "      <th>across_multiple</th>\n",
       "      <th>act</th>\n",
       "      <th>act_as</th>\n",
       "      <th>action</th>\n",
       "      <th>actionable</th>\n",
       "      <th>actionable_insight</th>\n",
       "      <th>active</th>\n",
       "      <th>actively</th>\n",
       "      <th>activity</th>\n",
       "      <th>actuarial</th>\n",
       "      <th>ad</th>\n",
       "      <th>ad_-_hoc</th>\n",
       "      <th>adapt</th>\n",
       "      <th>add</th>\n",
       "      <th>add_value</th>\n",
       "      <th>additional</th>\n",
       "      <th>address</th>\n",
       "      <th>adept</th>\n",
       "      <th>administration</th>\n",
       "      <th>adobe</th>\n",
       "      <th>...</th>\n",
       "      <th>usage</th>\n",
       "      <th>use</th>\n",
       "      <th>useful</th>\n",
       "      <th>user</th>\n",
       "      <th>utilise</th>\n",
       "      <th>utility</th>\n",
       "      <th>utilize</th>\n",
       "      <th>ux</th>\n",
       "      <th>vacancy</th>\n",
       "      <th>valid</th>\n",
       "      <th>validate</th>\n",
       "      <th>validation</th>\n",
       "      <th>valuable</th>\n",
       "      <th>value</th>\n",
       "      <th>varied</th>\n",
       "      <th>variety_of</th>\n",
       "      <th>various</th>\n",
       "      <th>vary</th>\n",
       "      <th>vast</th>\n",
       "      <th>vendor</th>\n",
       "      <th>verbal</th>\n",
       "      <th>verbal_communication_skill</th>\n",
       "      <th>verify</th>\n",
       "      <th>version</th>\n",
       "      <th>vertical</th>\n",
       "      <th>very_strong</th>\n",
       "      <th>veteran</th>\n",
       "      <th>vibrant</th>\n",
       "      <th>victoria</th>\n",
       "      <th>victorian</th>\n",
       "      <th>video</th>\n",
       "      <th>view</th>\n",
       "      <th>visa</th>\n",
       "      <th>vision</th>\n",
       "      <th>visit</th>\n",
       "      <th>visual</th>\n",
       "      <th>visualisation</th>\n",
       "      <th>visualisation_tool</th>\n",
       "      <th>visualise</th>\n",
       "      <th>visualization_tool</th>\n",
       "      <th>vital</th>\n",
       "      <th>voice</th>\n",
       "      <th>volume</th>\n",
       "      <th>volunteer</th>\n",
       "      <th>want</th>\n",
       "      <th>warehouse</th>\n",
       "      <th>warehousing</th>\n",
       "      <th>water</th>\n",
       "      <th>way</th>\n",
       "      <th>web</th>\n",
       "      <th>website</th>\n",
       "      <th>week</th>\n",
       "      <th>weekly</th>\n",
       "      <th>welcome</th>\n",
       "      <th>wellbeing</th>\n",
       "      <th>wellness</th>\n",
       "      <th>west</th>\n",
       "      <th>whilst</th>\n",
       "      <th>who_can</th>\n",
       "      <th>who_enjoy</th>\n",
       "      <th>who_want</th>\n",
       "      <th>wide</th>\n",
       "      <th>wide_variety</th>\n",
       "      <th>will_also</th>\n",
       "      <th>will_be_responsible</th>\n",
       "      <th>willing</th>\n",
       "      <th>willingness</th>\n",
       "      <th>win</th>\n",
       "      <th>windows</th>\n",
       "      <th>woman</th>\n",
       "      <th>word</th>\n",
       "      <th>work</th>\n",
       "      <th>work180</th>\n",
       "      <th>work_alongside</th>\n",
       "      <th>work_closely_with</th>\n",
       "      <th>work_collaboratively</th>\n",
       "      <th>work_with</th>\n",
       "      <th>workflow</th>\n",
       "      <th>workforce</th>\n",
       "      <th>working</th>\n",
       "      <th>working_environment</th>\n",
       "      <th>working_right</th>\n",
       "      <th>workload</th>\n",
       "      <th>workplace</th>\n",
       "      <th>workshop</th>\n",
       "      <th>world</th>\n",
       "      <th>worldwide</th>\n",
       "      <th>would_be</th>\n",
       "      <th>would_love</th>\n",
       "      <th>write</th>\n",
       "      <th>write_communication_skill</th>\n",
       "      <th>writing</th>\n",
       "      <th>written</th>\n",
       "      <th>xgboost</th>\n",
       "      <th>xml</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>young</th>\n",
       "      <th>|</th>\n",
       "      <th>â€™s</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>control</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>data_engineer</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.352941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>data_scientist</td>\n",
       "      <td>0.094017</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.068376</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.085470</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.059829</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.017094</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.017094</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.059829</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.068376</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.085470</td>\n",
       "      <td>0.059829</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.068376</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.059829</td>\n",
       "      <td>0.094017</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.085470</td>\n",
       "      <td>0.504274</td>\n",
       "      <td>0.094017</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.068376</td>\n",
       "      <td>0.094017</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>0.059829</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>0.017094</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.059829</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.017094</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.145299</td>\n",
       "      <td>0.017094</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.085470</td>\n",
       "      <td>0.017094</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.085470</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.145299</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.059829</td>\n",
       "      <td>0.136752</td>\n",
       "      <td>0.059829</td>\n",
       "      <td>0.017094</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.085470</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.145299</td>\n",
       "      <td>0.017094</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.632479</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.170940</td>\n",
       "      <td>0.094017</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.059829</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.094017</td>\n",
       "      <td>0.059829</td>\n",
       "      <td>0.085470</td>\n",
       "      <td>0.341880</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.017094</td>\n",
       "      <td>0.145299</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.094017</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.059829</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.059829</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.017094</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>0.059829</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.188034</td>\n",
       "      <td>0.059829</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.017094</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.068376</td>\n",
       "      <td>0.170940</td>\n",
       "      <td>0.017094</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.282051</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.059829</td>\n",
       "      <td>0.017094</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>0.094017</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.017094</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.068376</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.017094</td>\n",
       "      <td>0.170940</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.162393</td>\n",
       "      <td>0.162393</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.188034</td>\n",
       "      <td>0.094017</td>\n",
       "      <td>0.581197</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.068376</td>\n",
       "      <td>0.136752</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.068376</td>\n",
       "      <td>0.059829</td>\n",
       "      <td>0.213675</td>\n",
       "      <td>0.068376</td>\n",
       "      <td>0.119658</td>\n",
       "      <td>0.085470</td>\n",
       "      <td>0.188034</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.068376</td>\n",
       "      <td>0.068376</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.017094</td>\n",
       "      <td>0.264957</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.059829</td>\n",
       "      <td>0.299145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 2218 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       $        's         +       +61    -_edge  -_making  \\\n",
       "job_type                                                                     \n",
       "control         0.264706  0.411765  0.058824  0.029412  0.029412  0.058824   \n",
       "data_engineer   0.088235  0.264706  0.176471  0.058824  0.058824  0.058824   \n",
       "data_scientist  0.094017  0.222222  0.153846  0.034188  0.042735  0.042735   \n",
       "\n",
       "                -_minded  -_orient    -_term  /_life_balance        02  \\\n",
       "job_type                                                                 \n",
       "control         0.058824  0.029412  0.088235        0.147059  0.058824   \n",
       "data_engineer   0.058824  0.176471  0.058824        0.058824  0.029412   \n",
       "data_scientist  0.051282  0.051282  0.051282        0.034188  0.051282   \n",
       "\n",
       "                      03        08         1        10    10,000       100  \\\n",
       "job_type                                                                     \n",
       "control         0.058824  0.058824  0.088235  0.058824  0.058824  0.058824   \n",
       "data_engineer   0.117647  0.029412  0.088235  0.058824  0.029412  0.088235   \n",
       "data_scientist  0.068376  0.025641  0.085470  0.034188  0.025641  0.025641   \n",
       "\n",
       "                 10_year        12  12_month        13        15         2  \\\n",
       "job_type                                                                     \n",
       "control         0.029412  0.029412  0.117647  0.029412  0.117647  0.176471   \n",
       "data_engineer   0.029412  0.029412  0.058824  0.029412  0.058824  0.088235   \n",
       "data_scientist  0.059829  0.034188  0.017094  0.042735  0.008547  0.051282   \n",
       "\n",
       "                    2012      2017      2018      2019      2020        24  \\\n",
       "job_type                                                                     \n",
       "control         0.058824  0.088235  0.088235  0.235294  0.029412  0.029412   \n",
       "data_engineer   0.058824  0.029412  0.029412  0.176471  0.029412  0.029412   \n",
       "data_scientist  0.017094  0.025641  0.042735  0.059829  0.042735  0.034188   \n",
       "\n",
       "                  2_year         3        30  3_+_year    3_year         4  \\\n",
       "job_type                                                                     \n",
       "control         0.029412  0.117647  0.088235  0.029412  0.147059  0.205882   \n",
       "data_engineer   0.088235  0.058824  0.058824  0.117647  0.058824  0.117647   \n",
       "data_scientist  0.042735  0.068376  0.025641  0.076923  0.034188  0.034188   \n",
       "\n",
       "                      40  4_+_year         5        50  5_+_year    5_year  \\\n",
       "job_type                                                                     \n",
       "control         0.058824  0.088235  0.147059  0.029412  0.058824  0.088235   \n",
       "data_engineer   0.058824  0.058824  0.088235  0.058824  0.088235  0.058824   \n",
       "data_scientist  0.034188  0.034188  0.042735  0.034188  0.085470  0.059829   \n",
       "\n",
       "                       6   6_month         7        70      7370         8  \\\n",
       "job_type                                                                     \n",
       "control         0.058824  0.058824  0.088235  0.058824  0.029412  0.058824   \n",
       "data_engineer   0.058824  0.058824  0.088235  0.029412  0.029412  0.029412   \n",
       "data_scientist  0.076923  0.042735  0.068376  0.025641  0.042735  0.034188   \n",
       "\n",
       "                    8637         9     a_/_b  a_difference     a_few  \\\n",
       "job_type                                                               \n",
       "control         0.029412  0.088235  0.058824      0.117647  0.058824   \n",
       "data_engineer   0.029412  0.029412  0.058824      0.058824  0.117647   \n",
       "data_scientist  0.042735  0.034188  0.059829      0.094017  0.051282   \n",
       "\n",
       "                a_range_of  a_variety_of  a_wide_range   ability  ability_to  \\\n",
       "job_type                                                                       \n",
       "control           0.235294      0.058824      0.117647  0.117647    0.735294   \n",
       "data_engineer     0.294118      0.205882      0.117647  0.058824    0.558824   \n",
       "data_scientist    0.102564      0.153846      0.051282  0.085470    0.504274   \n",
       "\n",
       "                 able_to  aboriginal  about_us  academic  accelerate  \\\n",
       "job_type                                                               \n",
       "control         0.205882    0.088235  0.029412  0.117647    0.029412   \n",
       "data_engineer   0.088235    0.058824  0.088235  0.029412    0.147059   \n",
       "data_scientist  0.094017    0.042735  0.068376  0.094017    0.008547   \n",
       "\n",
       "                  accept    access  accessibility  accessible  accomplish  \\\n",
       "job_type                                                                    \n",
       "control         0.088235  0.088235       0.058824    0.058824    0.029412   \n",
       "data_engineer   0.117647  0.205882       0.088235    0.147059    0.029412   \n",
       "data_scientist  0.059829  0.111111       0.008547    0.017094    0.034188   \n",
       "\n",
       "                  accord  accordance   account  accountability  accountable  \\\n",
       "job_type                                                                      \n",
       "control         0.029412    0.029412  0.088235        0.088235     0.058824   \n",
       "data_engineer   0.029412    0.058824  0.058824        0.088235     0.058824   \n",
       "data_scientist  0.034188    0.042735  0.059829        0.051282     0.017094   \n",
       "\n",
       "                accounting  accuracy  accurate  accurately   achieve  \\\n",
       "job_type                                                               \n",
       "control           0.117647  0.058824  0.029412    0.029412  0.147059   \n",
       "data_engineer     0.029412  0.088235  0.058824    0.029412  0.117647   \n",
       "data_scientist    0.008547  0.128205  0.034188    0.034188  0.145299   \n",
       "\n",
       "                 acquire  acquisition  across_a_range  across_multiple  \\\n",
       "job_type                                                                 \n",
       "control         0.058824     0.088235        0.117647         0.176471   \n",
       "data_engineer   0.147059     0.058824        0.029412         0.176471   \n",
       "data_scientist  0.017094     0.042735        0.042735         0.085470   \n",
       "\n",
       "                     act    act_as    action  actionable  actionable_insight  \\\n",
       "job_type                                                                       \n",
       "control         0.088235  0.088235  0.117647    0.029412            0.029412   \n",
       "data_engineer   0.088235  0.029412  0.029412    0.088235            0.058824   \n",
       "data_scientist  0.017094  0.042735  0.085470    0.076923            0.145299   \n",
       "\n",
       "                  active  actively  activity  actuarial        ad  ad_-_hoc  \\\n",
       "job_type                                                                      \n",
       "control         0.088235  0.176471  0.294118   0.029412  0.088235  0.058824   \n",
       "data_engineer   0.058824  0.058824  0.117647   0.029412  0.029412  0.117647   \n",
       "data_scientist  0.076923  0.059829  0.136752   0.059829  0.017094  0.051282   \n",
       "\n",
       "                   adapt       add  add_value  additional   address     adept  \\\n",
       "job_type                                                                        \n",
       "control         0.088235  0.029412   0.088235    0.176471  0.117647  0.088235   \n",
       "data_engineer   0.147059  0.088235   0.058824    0.029412  0.117647  0.029412   \n",
       "data_scientist  0.076923  0.085470   0.034188    0.076923  0.145299  0.017094   \n",
       "\n",
       "                administration     adobe  ...     usage       use    useful  \\\n",
       "job_type                                  ...                                 \n",
       "control               0.147059  0.117647  ...  0.029412  0.441176  0.029412   \n",
       "data_engineer         0.058824  0.029412  ...  0.029412  0.588235  0.088235   \n",
       "data_scientist        0.042735  0.008547  ...  0.042735  0.632479  0.042735   \n",
       "\n",
       "                    user   utilise   utility   utilize        ux   vacancy  \\\n",
       "job_type                                                                     \n",
       "control         0.117647  0.029412  0.029412  0.029412  0.088235  0.029412   \n",
       "data_engineer   0.147059  0.058824  0.058824  0.058824  0.088235  0.029412   \n",
       "data_scientist  0.170940  0.094017  0.025641  0.025641  0.025641  0.059829   \n",
       "\n",
       "                   valid  validate  validation  valuable     value    varied  \\\n",
       "job_type                                                                       \n",
       "control         0.029412  0.029412    0.029412  0.058824  0.294118  0.176471   \n",
       "data_engineer   0.117647  0.029412    0.058824  0.117647  0.411765  0.088235   \n",
       "data_scientist  0.034188  0.094017    0.059829  0.085470  0.341880  0.025641   \n",
       "\n",
       "                variety_of   various      vary      vast    vendor    verbal  \\\n",
       "job_type                                                                       \n",
       "control           0.088235  0.117647  0.058824  0.029412  0.058824  0.058824   \n",
       "data_engineer     0.147059  0.235294  0.029412  0.058824  0.058824  0.088235   \n",
       "data_scientist    0.017094  0.145299  0.051282  0.042735  0.025641  0.094017   \n",
       "\n",
       "                verbal_communication_skill    verify   version  vertical  \\\n",
       "job_type                                                                   \n",
       "control                           0.117647  0.029412  0.058824  0.029412   \n",
       "data_engineer                     0.058824  0.058824  0.029412  0.088235   \n",
       "data_scientist                    0.076923  0.034188  0.059829  0.051282   \n",
       "\n",
       "                very_strong   veteran   vibrant  victoria  victorian  \\\n",
       "job_type                                                               \n",
       "control            0.058824  0.088235  0.088235  0.088235   0.088235   \n",
       "data_engineer      0.058824  0.058824  0.029412  0.029412   0.029412   \n",
       "data_scientist     0.059829  0.051282  0.034188  0.025641   0.017094   \n",
       "\n",
       "                   video      view      visa    vision     visit    visual  \\\n",
       "job_type                                                                     \n",
       "control         0.058824  0.176471  0.029412  0.147059  0.147059  0.029412   \n",
       "data_engineer   0.088235  0.117647  0.088235  0.058824  0.088235  0.029412   \n",
       "data_scientist  0.042735  0.102564  0.051282  0.128205  0.059829  0.034188   \n",
       "\n",
       "                visualisation  visualisation_tool  visualise  \\\n",
       "job_type                                                       \n",
       "control              0.029412            0.029412   0.029412   \n",
       "data_engineer        0.117647            0.058824   0.088235   \n",
       "data_scientist       0.188034            0.059829   0.042735   \n",
       "\n",
       "                visualization_tool     vital     voice    volume  volunteer  \\\n",
       "job_type                                                                      \n",
       "control                   0.029412  0.117647  0.117647  0.058824   0.029412   \n",
       "data_engineer             0.058824  0.058824  0.058824  0.058824   0.029412   \n",
       "data_scientist            0.042735  0.017094  0.034188  0.034188   0.068376   \n",
       "\n",
       "                    want  warehouse  warehousing     water       way  \\\n",
       "job_type                                                               \n",
       "control         0.235294   0.029412     0.029412  0.029412  0.352941   \n",
       "data_engineer   0.235294   0.205882     0.205882  0.058824  0.294118   \n",
       "data_scientist  0.170940   0.017094     0.008547  0.034188  0.282051   \n",
       "\n",
       "                     web   website      week    weekly   welcome  wellbeing  \\\n",
       "job_type                                                                      \n",
       "control         0.088235  0.117647  0.147059  0.058824  0.176471   0.088235   \n",
       "data_engineer   0.088235  0.088235  0.176471  0.088235  0.176471   0.117647   \n",
       "data_scientist  0.111111  0.059829  0.017094  0.008547  0.094017   0.042735   \n",
       "\n",
       "                wellness      west    whilst   who_can  who_enjoy  who_want  \\\n",
       "job_type                                                                      \n",
       "control         0.088235  0.058824  0.147059  0.117647   0.029412  0.058824   \n",
       "data_engineer   0.029412  0.058824  0.117647  0.058824   0.088235  0.117647   \n",
       "data_scientist  0.034188  0.017094  0.034188  0.068376   0.042735  0.017094   \n",
       "\n",
       "                    wide  wide_variety  will_also  will_be_responsible  \\\n",
       "job_type                                                                 \n",
       "control         0.147059      0.029412   0.176471             0.176471   \n",
       "data_engineer   0.058824      0.058824   0.205882             0.117647   \n",
       "data_scientist  0.170940      0.051282   0.162393             0.162393   \n",
       "\n",
       "                 willing  willingness       win   windows     woman      word  \\\n",
       "job_type                                                                        \n",
       "control         0.058824     0.058824  0.088235  0.088235  0.058824  0.117647   \n",
       "data_engineer   0.029412     0.088235  0.029412  0.088235  0.029412  0.058824   \n",
       "data_scientist  0.051282     0.042735  0.042735  0.008547  0.034188  0.051282   \n",
       "\n",
       "                    work   work180  work_alongside  work_closely_with  \\\n",
       "job_type                                                                \n",
       "control         0.882353  0.029412        0.058824           0.205882   \n",
       "data_engineer   0.823529  0.029412        0.117647           0.117647   \n",
       "data_scientist  0.871795  0.034188        0.076923           0.188034   \n",
       "\n",
       "                work_collaboratively  work_with  workflow  workforce  \\\n",
       "job_type                                                               \n",
       "control                     0.147059   0.470588  0.058824   0.088235   \n",
       "data_engineer               0.058824   0.558824  0.176471   0.058824   \n",
       "data_scientist              0.094017   0.581197  0.051282   0.068376   \n",
       "\n",
       "                 working  working_environment  working_right  workload  \\\n",
       "job_type                                                                 \n",
       "control         0.205882             0.058824       0.029412  0.088235   \n",
       "data_engineer   0.205882             0.058824       0.058824  0.117647   \n",
       "data_scientist  0.136752             0.051282       0.051282  0.025641   \n",
       "\n",
       "                workplace  workshop     world  worldwide  would_be  \\\n",
       "job_type                                                             \n",
       "control          0.147059  0.088235  0.264706   0.058824  0.147059   \n",
       "data_engineer    0.117647  0.058824  0.264706   0.058824  0.117647   \n",
       "data_scientist   0.068376  0.059829  0.213675   0.068376  0.119658   \n",
       "\n",
       "                would_love     write  write_communication_skill   writing  \\\n",
       "job_type                                                                    \n",
       "control           0.029412  0.235294                   0.117647  0.117647   \n",
       "data_engineer     0.088235  0.147059                   0.088235  0.058824   \n",
       "data_scientist    0.085470  0.188034                   0.051282  0.068376   \n",
       "\n",
       "                 written   xgboost       xml      year       yes     young  \\\n",
       "job_type                                                                     \n",
       "control         0.058824  0.029412  0.029412  0.382353  0.029412  0.058824   \n",
       "data_engineer   0.058824  0.029412  0.088235  0.382353  0.029412  0.058824   \n",
       "data_scientist  0.068376  0.034188  0.017094  0.264957  0.034188  0.034188   \n",
       "\n",
       "                       |        â€™s  \n",
       "job_type                            \n",
       "control         0.029412  0.294118  \n",
       "data_engineer   0.088235  0.352941  \n",
       "data_scientist  0.059829  0.299145  \n",
       "\n",
       "[3 rows x 2218 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_df = get_term_probability(term_freq_df)\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>term</th>\n",
       "      <th>control</th>\n",
       "      <th>data_engineer</th>\n",
       "      <th>data_scientist</th>\n",
       "      <th>data_engineer_lift</th>\n",
       "      <th>data_scientist_lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>experience</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.931624</td>\n",
       "      <td>1.066667</td>\n",
       "      <td>1.055840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>work</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.988034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>team</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>1.148148</td>\n",
       "      <td>1.076290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>provide</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.670611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>role</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.623932</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.815911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>include</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.598291</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.813675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ability_to</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.504274</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.685812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>opportunity</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.732308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>strong</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.495726</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.766123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>people</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.282051</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.435897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "term          control  data_engineer  data_scientist  data_engineer_lift  \\\n",
       "experience   0.882353       0.941176        0.931624            1.066667   \n",
       "work         0.882353       0.823529        0.871795            0.933333   \n",
       "team         0.794118       0.911765        0.854701            1.148148   \n",
       "provide      0.764706       0.529412        0.512821            0.692308   \n",
       "role         0.764706       0.764706        0.623932            1.000000   \n",
       "include      0.735294       0.558824        0.598291            0.760000   \n",
       "ability_to   0.735294       0.558824        0.504274            0.760000   \n",
       "opportunity  0.735294       0.558824        0.538462            0.760000   \n",
       "strong       0.647059       0.588235        0.495726            0.909091   \n",
       "people       0.647059       0.500000        0.282051            0.772727   \n",
       "\n",
       "term         data_scientist_lift  \n",
       "experience              1.055840  \n",
       "work                    0.988034  \n",
       "team                    1.076290  \n",
       "provide                 0.670611  \n",
       "role                    0.815911  \n",
       "include                 0.813675  \n",
       "ability_to              0.685812  \n",
       "opportunity             0.732308  \n",
       "strong                  0.766123  \n",
       "people                  0.435897  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add in the lift and transpose to get long not wide dataframe\n",
    "stats_df = get_lift(stats_df)\n",
    "stats_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "for col in ['data_scientist', 'data_engineer']:\n",
    "    input_lift = stats_df[f'{col}_lift'].apply(\n",
    "        lambda x: max(1, x)\n",
    "    ).values\n",
    "    scaler = MinMaxScaler()\n",
    "    stats_df[f'{col}_lift_scaled'] = scaler.fit_transform(input_lift.reshape(-1, 1))\n",
    "    stats_df[f'{col}_score'] = stats_df[[col, f'{col}_lift_scaled']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file\n",
    "stats_df.to_csv(PARAMS['CLEANED_PATH'] / 'stats.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Top skills by document frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For data science:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>term</th>\n",
       "      <th>control</th>\n",
       "      <th>data_engineer</th>\n",
       "      <th>data_scientist</th>\n",
       "      <th>data_engineer_lift</th>\n",
       "      <th>data_scientist_lift</th>\n",
       "      <th>data_scientist_lift_scaled</th>\n",
       "      <th>data_scientist_score</th>\n",
       "      <th>data_engineer_lift_scaled</th>\n",
       "      <th>data_engineer_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>python</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>23.0</td>\n",
       "      <td>26.444444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.838235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>machine_learning</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>12.0</td>\n",
       "      <td>26.153846</td>\n",
       "      <td>0.988579</td>\n",
       "      <td>0.878905</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.426471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>statistics</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.923077</td>\n",
       "      <td>0.783003</td>\n",
       "      <td>0.699194</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.164439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>r</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.923077</td>\n",
       "      <td>0.783003</td>\n",
       "      <td>0.699194</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.201872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mathematics</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.401709</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.658120</td>\n",
       "      <td>0.497481</td>\n",
       "      <td>0.449595</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.052139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>spark</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.282051</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.589744</td>\n",
       "      <td>0.337588</td>\n",
       "      <td>0.309820</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.613636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sql</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>11.5</td>\n",
       "      <td>9.153846</td>\n",
       "      <td>0.320457</td>\n",
       "      <td>0.429459</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.576872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>predictive_modelling</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.247863</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.427350</td>\n",
       "      <td>0.291905</td>\n",
       "      <td>0.269884</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>scala</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.846154</td>\n",
       "      <td>0.269063</td>\n",
       "      <td>0.249916</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.351604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>java</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.555556</td>\n",
       "      <td>0.257642</td>\n",
       "      <td>0.239932</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.389037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>algorithm</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.555556</td>\n",
       "      <td>0.257642</td>\n",
       "      <td>0.239932</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.089572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>technique</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.427350</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.264957</td>\n",
       "      <td>0.246221</td>\n",
       "      <td>0.336786</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.185829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tableau</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.213675</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.264957</td>\n",
       "      <td>0.246221</td>\n",
       "      <td>0.229948</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.052139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>visualisation</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.188034</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.393162</td>\n",
       "      <td>0.211958</td>\n",
       "      <td>0.199996</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.127005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>extract</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.102564</td>\n",
       "      <td>0.200537</td>\n",
       "      <td>0.190012</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.127005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>method</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.102564</td>\n",
       "      <td>0.200537</td>\n",
       "      <td>0.190012</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.201872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>problem</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.350427</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.957265</td>\n",
       "      <td>0.194827</td>\n",
       "      <td>0.272627</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.185829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>computer_science</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.341880</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.811966</td>\n",
       "      <td>0.189117</td>\n",
       "      <td>0.265498</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.107620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hadoop</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.170940</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.811966</td>\n",
       "      <td>0.189117</td>\n",
       "      <td>0.180028</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.501337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>deep_learning</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.170940</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.811966</td>\n",
       "      <td>0.189117</td>\n",
       "      <td>0.180028</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.089572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>predictive</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.162393</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.521368</td>\n",
       "      <td>0.177696</td>\n",
       "      <td>0.170044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>advanced_analytic</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.230769</td>\n",
       "      <td>0.166275</td>\n",
       "      <td>0.160060</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.127005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dataset</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.230769</td>\n",
       "      <td>0.166275</td>\n",
       "      <td>0.160060</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.164439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>actionable_insight</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.145299</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.940171</td>\n",
       "      <td>0.154854</td>\n",
       "      <td>0.150077</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.052139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>c</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.145299</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.940171</td>\n",
       "      <td>0.154854</td>\n",
       "      <td>0.150077</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.164439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "term                   control  data_engineer  data_scientist  \\\n",
       "python                0.029412       0.676471        0.777778   \n",
       "machine_learning      0.029412       0.352941        0.769231   \n",
       "statistics            0.029412       0.147059        0.615385   \n",
       "r                     0.029412       0.176471        0.615385   \n",
       "mathematics           0.029412       0.058824        0.401709   \n",
       "spark                 0.029412       0.500000        0.282051   \n",
       "sql                   0.058824       0.676471        0.538462   \n",
       "predictive_modelling  0.029412       0.029412        0.247863   \n",
       "scala                 0.029412       0.294118        0.230769   \n",
       "java                  0.029412       0.323529        0.222222   \n",
       "algorithm             0.029412       0.088235        0.222222   \n",
       "technique             0.058824       0.235294        0.427350   \n",
       "tableau               0.029412       0.058824        0.213675   \n",
       "visualisation         0.029412       0.117647        0.188034   \n",
       "extract               0.029412       0.117647        0.179487   \n",
       "method                0.029412       0.176471        0.179487   \n",
       "problem               0.058824       0.235294        0.350427   \n",
       "computer_science      0.058824       0.147059        0.341880   \n",
       "hadoop                0.029412       0.411765        0.170940   \n",
       "deep_learning         0.029412       0.088235        0.170940   \n",
       "predictive            0.029412       0.029412        0.162393   \n",
       "advanced_analytic     0.029412       0.117647        0.153846   \n",
       "dataset               0.029412       0.147059        0.153846   \n",
       "actionable_insight    0.029412       0.058824        0.145299   \n",
       "c                     0.029412       0.147059        0.145299   \n",
       "\n",
       "term                  data_engineer_lift  data_scientist_lift  \\\n",
       "python                              23.0            26.444444   \n",
       "machine_learning                    12.0            26.153846   \n",
       "statistics                           5.0            20.923077   \n",
       "r                                    6.0            20.923077   \n",
       "mathematics                          2.0            13.658120   \n",
       "spark                               17.0             9.589744   \n",
       "sql                                 11.5             9.153846   \n",
       "predictive_modelling                 1.0             8.427350   \n",
       "scala                               10.0             7.846154   \n",
       "java                                11.0             7.555556   \n",
       "algorithm                            3.0             7.555556   \n",
       "technique                            4.0             7.264957   \n",
       "tableau                              2.0             7.264957   \n",
       "visualisation                        4.0             6.393162   \n",
       "extract                              4.0             6.102564   \n",
       "method                               6.0             6.102564   \n",
       "problem                              4.0             5.957265   \n",
       "computer_science                     2.5             5.811966   \n",
       "hadoop                              14.0             5.811966   \n",
       "deep_learning                        3.0             5.811966   \n",
       "predictive                           1.0             5.521368   \n",
       "advanced_analytic                    4.0             5.230769   \n",
       "dataset                              5.0             5.230769   \n",
       "actionable_insight                   2.0             4.940171   \n",
       "c                                    5.0             4.940171   \n",
       "\n",
       "term                  data_scientist_lift_scaled  data_scientist_score  \\\n",
       "python                                  1.000000              0.888889   \n",
       "machine_learning                        0.988579              0.878905   \n",
       "statistics                              0.783003              0.699194   \n",
       "r                                       0.783003              0.699194   \n",
       "mathematics                             0.497481              0.449595   \n",
       "spark                                   0.337588              0.309820   \n",
       "sql                                     0.320457              0.429459   \n",
       "predictive_modelling                    0.291905              0.269884   \n",
       "scala                                   0.269063              0.249916   \n",
       "java                                    0.257642              0.239932   \n",
       "algorithm                               0.257642              0.239932   \n",
       "technique                               0.246221              0.336786   \n",
       "tableau                                 0.246221              0.229948   \n",
       "visualisation                           0.211958              0.199996   \n",
       "extract                                 0.200537              0.190012   \n",
       "method                                  0.200537              0.190012   \n",
       "problem                                 0.194827              0.272627   \n",
       "computer_science                        0.189117              0.265498   \n",
       "hadoop                                  0.189117              0.180028   \n",
       "deep_learning                           0.189117              0.180028   \n",
       "predictive                              0.177696              0.170044   \n",
       "advanced_analytic                       0.166275              0.160060   \n",
       "dataset                                 0.166275              0.160060   \n",
       "actionable_insight                      0.154854              0.150077   \n",
       "c                                       0.154854              0.150077   \n",
       "\n",
       "term                  data_engineer_lift_scaled  data_engineer_score  \n",
       "python                                 1.000000             0.838235  \n",
       "machine_learning                       0.500000             0.426471  \n",
       "statistics                             0.181818             0.164439  \n",
       "r                                      0.227273             0.201872  \n",
       "mathematics                            0.045455             0.052139  \n",
       "spark                                  0.727273             0.613636  \n",
       "sql                                    0.477273             0.576872  \n",
       "predictive_modelling                   0.000000             0.014706  \n",
       "scala                                  0.409091             0.351604  \n",
       "java                                   0.454545             0.389037  \n",
       "algorithm                              0.090909             0.089572  \n",
       "technique                              0.136364             0.185829  \n",
       "tableau                                0.045455             0.052139  \n",
       "visualisation                          0.136364             0.127005  \n",
       "extract                                0.136364             0.127005  \n",
       "method                                 0.227273             0.201872  \n",
       "problem                                0.136364             0.185829  \n",
       "computer_science                       0.068182             0.107620  \n",
       "hadoop                                 0.590909             0.501337  \n",
       "deep_learning                          0.090909             0.089572  \n",
       "predictive                             0.000000             0.014706  \n",
       "advanced_analytic                      0.136364             0.127005  \n",
       "dataset                                0.181818             0.164439  \n",
       "actionable_insight                     0.045455             0.052139  \n",
       "c                                      0.181818             0.164439  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_df.sort_values('data_scientist_lift', ascending=False).drop('data_science').head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data engineering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>term</th>\n",
       "      <th>control</th>\n",
       "      <th>data_engineer</th>\n",
       "      <th>data_scientist</th>\n",
       "      <th>data_engineer_lift</th>\n",
       "      <th>data_scientist_lift</th>\n",
       "      <th>data_scientist_lift_scaled</th>\n",
       "      <th>data_scientist_score</th>\n",
       "      <th>data_engineer_lift_scaled</th>\n",
       "      <th>data_engineer_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>python</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>23.0</td>\n",
       "      <td>26.444444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.838235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>spark</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.282051</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.589744</td>\n",
       "      <td>0.337588</td>\n",
       "      <td>0.309820</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.613636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>etl</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.068376</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.324786</td>\n",
       "      <td>0.052066</td>\n",
       "      <td>0.060221</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.538770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>processing</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.487179</td>\n",
       "      <td>0.097749</td>\n",
       "      <td>0.100157</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.501337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hadoop</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.170940</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.811966</td>\n",
       "      <td>0.189117</td>\n",
       "      <td>0.180028</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.501337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>data_pipeline</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.452991</td>\n",
       "      <td>0.017803</td>\n",
       "      <td>0.030269</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.463904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>machine_learning</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>12.0</td>\n",
       "      <td>26.153846</td>\n",
       "      <td>0.988579</td>\n",
       "      <td>0.878905</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.426471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>data_lake</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.017094</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.581197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.426471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sql</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>11.5</td>\n",
       "      <td>9.153846</td>\n",
       "      <td>0.320457</td>\n",
       "      <td>0.429459</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.576872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big_data</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.273504</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.649573</td>\n",
       "      <td>0.143433</td>\n",
       "      <td>0.208469</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.550802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>java</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.555556</td>\n",
       "      <td>0.257642</td>\n",
       "      <td>0.239932</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.389037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kafka</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.452991</td>\n",
       "      <td>0.017803</td>\n",
       "      <td>0.030269</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.351604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>redshift</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.085470</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.905983</td>\n",
       "      <td>0.074908</td>\n",
       "      <td>0.080189</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.351604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>scala</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.846154</td>\n",
       "      <td>0.269063</td>\n",
       "      <td>0.249916</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.351604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>nosql</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.615385</td>\n",
       "      <td>0.063487</td>\n",
       "      <td>0.070205</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.351604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>query</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.777778</td>\n",
       "      <td>0.109170</td>\n",
       "      <td>0.110141</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.351604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>aws</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.196581</td>\n",
       "      <td>9.5</td>\n",
       "      <td>3.341880</td>\n",
       "      <td>0.092039</td>\n",
       "      <td>0.144310</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.472594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>api</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.615385</td>\n",
       "      <td>0.063487</td>\n",
       "      <td>0.070205</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.314171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pipeline</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.743590</td>\n",
       "      <td>0.029224</td>\n",
       "      <td>0.040253</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.314171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>programming_language</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.777778</td>\n",
       "      <td>0.109170</td>\n",
       "      <td>0.110141</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.314171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>data_warehouse</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.276738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>stream</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.162393</td>\n",
       "      <td>0.006382</td>\n",
       "      <td>0.020285</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.276738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>warehousing</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.290598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004274</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.239305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>informatica</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.290598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004274</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.239305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cloud</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.324786</td>\n",
       "      <td>0.052066</td>\n",
       "      <td>0.128597</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.445187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "term                   control  data_engineer  data_scientist  \\\n",
       "python                0.029412       0.676471        0.777778   \n",
       "spark                 0.029412       0.500000        0.282051   \n",
       "etl                   0.029412       0.441176        0.068376   \n",
       "processing            0.029412       0.411765        0.102564   \n",
       "hadoop                0.029412       0.411765        0.170940   \n",
       "data_pipeline         0.029412       0.382353        0.042735   \n",
       "machine_learning      0.029412       0.352941        0.769231   \n",
       "data_lake             0.029412       0.352941        0.017094   \n",
       "sql                   0.058824       0.676471        0.538462   \n",
       "big_data              0.058824       0.647059        0.273504   \n",
       "java                  0.029412       0.323529        0.222222   \n",
       "kafka                 0.029412       0.294118        0.042735   \n",
       "redshift              0.029412       0.294118        0.085470   \n",
       "scala                 0.029412       0.294118        0.230769   \n",
       "nosql                 0.029412       0.294118        0.076923   \n",
       "query                 0.029412       0.294118        0.111111   \n",
       "aws                   0.058824       0.558824        0.196581   \n",
       "api                   0.029412       0.264706        0.076923   \n",
       "pipeline              0.029412       0.264706        0.051282   \n",
       "programming_language  0.029412       0.264706        0.111111   \n",
       "data_warehouse        0.029412       0.235294        0.025641   \n",
       "stream                0.029412       0.235294        0.034188   \n",
       "warehousing           0.029412       0.205882        0.008547   \n",
       "informatica           0.029412       0.205882        0.008547   \n",
       "cloud                 0.088235       0.617647        0.205128   \n",
       "\n",
       "term                  data_engineer_lift  data_scientist_lift  \\\n",
       "python                              23.0            26.444444   \n",
       "spark                               17.0             9.589744   \n",
       "etl                                 15.0             2.324786   \n",
       "processing                          14.0             3.487179   \n",
       "hadoop                              14.0             5.811966   \n",
       "data_pipeline                       13.0             1.452991   \n",
       "machine_learning                    12.0            26.153846   \n",
       "data_lake                           12.0             0.581197   \n",
       "sql                                 11.5             9.153846   \n",
       "big_data                            11.0             4.649573   \n",
       "java                                11.0             7.555556   \n",
       "kafka                               10.0             1.452991   \n",
       "redshift                            10.0             2.905983   \n",
       "scala                               10.0             7.846154   \n",
       "nosql                               10.0             2.615385   \n",
       "query                               10.0             3.777778   \n",
       "aws                                  9.5             3.341880   \n",
       "api                                  9.0             2.615385   \n",
       "pipeline                             9.0             1.743590   \n",
       "programming_language                 9.0             3.777778   \n",
       "data_warehouse                       8.0             0.871795   \n",
       "stream                               8.0             1.162393   \n",
       "warehousing                          7.0             0.290598   \n",
       "informatica                          7.0             0.290598   \n",
       "cloud                                7.0             2.324786   \n",
       "\n",
       "term                  data_scientist_lift_scaled  data_scientist_score  \\\n",
       "python                                  1.000000              0.888889   \n",
       "spark                                   0.337588              0.309820   \n",
       "etl                                     0.052066              0.060221   \n",
       "processing                              0.097749              0.100157   \n",
       "hadoop                                  0.189117              0.180028   \n",
       "data_pipeline                           0.017803              0.030269   \n",
       "machine_learning                        0.988579              0.878905   \n",
       "data_lake                               0.000000              0.008547   \n",
       "sql                                     0.320457              0.429459   \n",
       "big_data                                0.143433              0.208469   \n",
       "java                                    0.257642              0.239932   \n",
       "kafka                                   0.017803              0.030269   \n",
       "redshift                                0.074908              0.080189   \n",
       "scala                                   0.269063              0.249916   \n",
       "nosql                                   0.063487              0.070205   \n",
       "query                                   0.109170              0.110141   \n",
       "aws                                     0.092039              0.144310   \n",
       "api                                     0.063487              0.070205   \n",
       "pipeline                                0.029224              0.040253   \n",
       "programming_language                    0.109170              0.110141   \n",
       "data_warehouse                          0.000000              0.012821   \n",
       "stream                                  0.006382              0.020285   \n",
       "warehousing                             0.000000              0.004274   \n",
       "informatica                             0.000000              0.004274   \n",
       "cloud                                   0.052066              0.128597   \n",
       "\n",
       "term                  data_engineer_lift_scaled  data_engineer_score  \n",
       "python                                 1.000000             0.838235  \n",
       "spark                                  0.727273             0.613636  \n",
       "etl                                    0.636364             0.538770  \n",
       "processing                             0.590909             0.501337  \n",
       "hadoop                                 0.590909             0.501337  \n",
       "data_pipeline                          0.545455             0.463904  \n",
       "machine_learning                       0.500000             0.426471  \n",
       "data_lake                              0.500000             0.426471  \n",
       "sql                                    0.477273             0.576872  \n",
       "big_data                               0.454545             0.550802  \n",
       "java                                   0.454545             0.389037  \n",
       "kafka                                  0.409091             0.351604  \n",
       "redshift                               0.409091             0.351604  \n",
       "scala                                  0.409091             0.351604  \n",
       "nosql                                  0.409091             0.351604  \n",
       "query                                  0.409091             0.351604  \n",
       "aws                                    0.386364             0.472594  \n",
       "api                                    0.363636             0.314171  \n",
       "pipeline                               0.363636             0.314171  \n",
       "programming_language                   0.363636             0.314171  \n",
       "data_warehouse                         0.318182             0.276738  \n",
       "stream                                 0.318182             0.276738  \n",
       "warehousing                            0.272727             0.239305  \n",
       "informatica                            0.272727             0.239305  \n",
       "cloud                                  0.272727             0.445187  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_df.sort_values('data_engineer_lift', ascending=False).drop('data_engineer').head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Top skills required on LinkedIn\n",
    "For LinkedIn, job advertisers can list explicit skills they're looking for. Count these up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def parse_comma_separated_list_string(string):\n",
    "    \"\"\"\n",
    "    Convert a comma-separated list of skills to a true list,\n",
    "    treating commas within quotation marks as not separators\n",
    "    \"\"\"\n",
    "    start_idx = 0\n",
    "    in_quotes = False\n",
    "    items = set()\n",
    "    \n",
    "    for i, char in enumerate(string):\n",
    "        if char in {'\"', 'â€œ', 'â€'}:\n",
    "            in_quotes = not in_quotes\n",
    "        elif char == ',':\n",
    "            if not in_quotes:\n",
    "                # Found a skill separator\n",
    "                item = string[start_idx:i].strip()\n",
    "                item = item.replace('\"', '').replace('â€œ', '').replace('â€', '')\n",
    "                items.add(item)\n",
    "                start_idx = i + 1\n",
    "    item = string[start_idx:].strip()\n",
    "    items.add(item.replace('\"', '').replace('â€œ', '').replace('â€', ''))\n",
    "    return items\n",
    "\n",
    "def get_skills_df(skills_series):\n",
    "    \"\"\"Take a series of skills and return a DataFrame indicating counts and probs\"\"\"\n",
    "    skills_series = skills_series[skills_series.notna()]\n",
    "    skillsets = skills_series.apply(parse_comma_separated_list_string)\n",
    "    \n",
    "    counter = Counter()\n",
    "    for skillset in skillsets:\n",
    "        counter.update(skillset)\n",
    "\n",
    "    skills_df = pd.DataFrame(\n",
    "        data=counter.most_common(),\n",
    "        columns=['skill', 'count']\n",
    "    ).sort_values('count', ascending=False)\n",
    "    skills_df['fraction'] = skills_df['count'] / skillsets.shape[0]\n",
    "    return skills_df\n",
    "\n",
    "def analyse_skill_reqs(required_skills, applicant_skills):\n",
    "    \"\"\"Assess skills explicitly called out against those offered by applicant\"\"\"\n",
    "    required_skills_df = get_skills_df(required_skills)\n",
    "    applicant_skills_df = get_skills_df(applicant_skills)\n",
    "\n",
    "    merge_df = required_skills_df.merge(\n",
    "        applicant_skills_df, on='skill', how='outer',\n",
    "        suffixes=('_required', '_applicant'),\n",
    "        validate='one_to_one'\n",
    "    )\n",
    "\n",
    "    merge_df['delta'] = merge_df['fraction_applicant'] - merge_df['fraction_required']\n",
    "    return merge_df.sort_values('fraction_required', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(136, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skill</th>\n",
       "      <th>count_required</th>\n",
       "      <th>fraction_required</th>\n",
       "      <th>count_applicant</th>\n",
       "      <th>fraction_applicant</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.358543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Data Mining</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>-0.105042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Python (Programming Language)</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.560224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Analytics</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>-0.292717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Data Analytics</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>-0.351541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>R</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.549020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Analytical Skills</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Statistical Modeling</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Problem Solving</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            skill  count_required  fraction_required  \\\n",
       "0                    Data Science            18.0           0.857143   \n",
       "1                Machine Learning            11.0           0.523810   \n",
       "2                     Data Mining             9.0           0.428571   \n",
       "3   Python (Programming Language)             8.0           0.380952   \n",
       "4                       Analytics             8.0           0.380952   \n",
       "5                  Data Analytics             8.0           0.380952   \n",
       "6                               R             7.0           0.333333   \n",
       "7               Analytical Skills             6.0           0.285714   \n",
       "8            Statistical Modeling             5.0           0.238095   \n",
       "10                Problem Solving             4.0           0.190476   \n",
       "\n",
       "    count_applicant  fraction_applicant     delta  \n",
       "0              17.0            0.500000 -0.357143  \n",
       "1              30.0            0.882353  0.358543  \n",
       "2              11.0            0.323529 -0.105042  \n",
       "3              32.0            0.941176  0.560224  \n",
       "4               3.0            0.088235 -0.292717  \n",
       "5               1.0            0.029412 -0.351541  \n",
       "6              30.0            0.882353  0.549020  \n",
       "7               NaN                 NaN       NaN  \n",
       "8               NaN                 NaN       NaN  \n",
       "10              NaN                 NaN       NaN  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasci_skills_df = analyse_skill_reqs(dfs['data_scientist']['required skills'],\n",
    "                                       dfs['data_scientist']['applicants skills'])\n",
    "\n",
    "print(datasci_skills_df.shape)\n",
    "datasci_skills_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasci_skills_df.to_csv(PARAMS['CLEANED_PATH'] / 'datasci_skills.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skill</th>\n",
       "      <th>count_required</th>\n",
       "      <th>fraction_required</th>\n",
       "      <th>count_applicant</th>\n",
       "      <th>fraction_applicant</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Amazon Web Services (AWS)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>-0.402778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Analytics</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Extract, Transform, Load (ETL)</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Apache Spark</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>-0.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>American Welding Society (AWS)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Scripting</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Data Mining</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Apache Kafka</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Big Data</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>PySpark</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             skill  count_required  fraction_required  \\\n",
       "0        Amazon Web Services (AWS)             5.0              0.625   \n",
       "2                        Analytics             4.0              0.500   \n",
       "3   Extract, Transform, Load (ETL)             4.0              0.500   \n",
       "1                     Apache Spark             4.0              0.500   \n",
       "4   American Welding Society (AWS)             3.0              0.375   \n",
       "12                       Scripting             2.0              0.250   \n",
       "18                     Data Mining             2.0              0.250   \n",
       "17                    Apache Kafka             2.0              0.250   \n",
       "15                        Big Data             2.0              0.250   \n",
       "14                         PySpark             2.0              0.250   \n",
       "\n",
       "    count_applicant  fraction_applicant     delta  \n",
       "0               2.0            0.222222 -0.402778  \n",
       "2               NaN                 NaN       NaN  \n",
       "3               3.0            0.333333 -0.166667  \n",
       "1               2.0            0.222222 -0.277778  \n",
       "4               NaN                 NaN       NaN  \n",
       "12              NaN                 NaN       NaN  \n",
       "18              NaN                 NaN       NaN  \n",
       "17              NaN                 NaN       NaN  \n",
       "15              3.0            0.333333  0.083333  \n",
       "14              NaN                 NaN       NaN  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataeng_skills_df = analyse_skill_reqs(dfs['data_engineer']['required skills'],\n",
    "                                       dfs['data_engineer']['applicants skills'])\n",
    "\n",
    "dataeng_skills_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataeng_skills_df.to_csv(PARAMS['CLEANED_PATH'] / 'dataeng_skills.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
