{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Trigram Phrase Model\n",
    "*David Norrish, October 2019*\n",
    "\n",
    "We will use Gensim to detect common bigrams and the trigrams from the corpus of job descriptions. The trigram model will be used in subsequent text processing steps so that concepts like \"statistical modelling\" can be reliably separated from \"data modelling\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"../data\")\n",
    "RAW_PATH = DATA_PATH / \"raw\"\n",
    "# Discovery all CSVs with job descriptions\n",
    "JOB_PATHS = list(RAW_PATH.glob(\"*jobs.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('../data/raw/data_engineer_jobs.csv'),\n",
       " PosixPath('../data/raw/control_jobs.csv'),\n",
       " PosixPath('../data/raw/data_scientist_jobs.csv')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JOB_PATHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in an example jobs CSV to see the structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in ../data/raw/data_engineer_jobs.csv:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>institution</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>required skills</th>\n",
       "      <th>applicants skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Data Pipeline Engineer</td>\n",
       "      <td>Data Processors</td>\n",
       "      <td>30/09/2019</td>\n",
       "      <td>Data Processors is a data centric research and technology services company. We offer a unique do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Aurecon</td>\n",
       "      <td>02/10/2019</td>\n",
       "      <td>At Aurecon we see the future through a very different lens. Do you?\\n\\nInnovation, eminence and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Senior Big Data Engineer SQL,Python experience, exp in AWS or Azure a must!</td>\n",
       "      <td>Counterpoint Group</td>\n",
       "      <td>02/10/2019</td>\n",
       "      <td>Our Client seeks people who are truly passionate about development within the Big Data space, wh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Senior Data Engineer, Melbourne</td>\n",
       "      <td>EY</td>\n",
       "      <td>23/09/2019</td>\n",
       "      <td>Variety of work and career development opportunities\\n    Choose a career that connects you ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Data Analyst or ETL Developer</td>\n",
       "      <td>Private Advertiser</td>\n",
       "      <td>03/10/2019</td>\n",
       "      <td>We are looking for a Data Analyst or Senior Data Analyst, or ETL Developer, Senior ETL, ETL Tech...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         title  \\\n",
       "0                                                       Data Pipeline Engineer   \n",
       "1                                                                Data Engineer   \n",
       "2  Senior Big Data Engineer SQL,Python experience, exp in AWS or Azure a must!   \n",
       "3                                              Senior Data Engineer, Melbourne   \n",
       "4                                                Data Analyst or ETL Developer   \n",
       "\n",
       "          institution        date  \\\n",
       "0     Data Processors  30/09/2019   \n",
       "1             Aurecon  02/10/2019   \n",
       "2  Counterpoint Group  02/10/2019   \n",
       "3                  EY  23/09/2019   \n",
       "4  Private Advertiser  03/10/2019   \n",
       "\n",
       "                                                                                                  text  \\\n",
       "0  Data Processors is a data centric research and technology services company. We offer a unique do...   \n",
       "1  At Aurecon we see the future through a very different lens. Do you?\\n\\nInnovation, eminence and ...   \n",
       "2  Our Client seeks people who are truly passionate about development within the Big Data space, wh...   \n",
       "3      Variety of work and career development opportunities\\n    Choose a career that connects you ...   \n",
       "4  We are looking for a Data Analyst or Senior Data Analyst, or ETL Developer, Senior ETL, ETL Tech...   \n",
       "\n",
       "  required skills applicants skills  \n",
       "0             NaN               NaN  \n",
       "1             NaN               NaN  \n",
       "2             NaN               NaN  \n",
       "3             NaN               NaN  \n",
       "4             NaN               NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Read in {JOB_PATHS[0]}:\")\n",
    "jobs_df = pd.read_csv(JOB_PATHS[0])\n",
    "jobs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the spaCy model that will be used to parse job descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.6 s, sys: 496 ms, total: 20.1 s\n",
      "Wall time: 20.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare text for phrase modelling\n",
    "Phrase modelling only needs to consider adjacent words within any given sentence, not documents as a whole or conssecutive sentences.\n",
    "\n",
    "As such, for all position descriptions, normalise the text (lemmatise, lower-case & drop punctuation), and save to a single file, with each sentence or bullet point on a separate line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a couple of generator functions to handle the cleaning\n",
    "def line_generator(df: DataFrame, col: str):\n",
    "    \"\"\"Generator for lines of text from a DataFrame column\"\"\"\n",
    "    for text in df[col]:\n",
    "        try:\n",
    "            text.split()\n",
    "            for line in text.split('\\n'):\n",
    "                yield line.strip()\n",
    "        except Exception:\n",
    "            print(type(text))\n",
    "            print(text)\n",
    "            breakpoint()                \n",
    "\n",
    "def parse_lines(df: DataFrame, col: str):\n",
    "    \"\"\"\n",
    "    spaCy-parse text in a DataFrame column line by line\n",
    "    \n",
    "    spaCy won't detect newlines as sentence boundaries, so must do this explicitly first\n",
    "    \"\"\"\n",
    "    for parsed_text in nlp.pipe(line_generator(df, col)):\n",
    "        for sent in parsed_text.sents:\n",
    "            yield ' '.join([token.lemma_.lower() for token in sent if not (token.is_punct or token.is_space)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEANED_PATH = DATA_PATH / \"cleaned\"\n",
    "LINES_PATH = CLEANED_PATH / \"normalised_jobs.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.8 s, sys: 328 ms, total: 13.1 s\n",
      "Wall time: 13.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if not LINES_PATH.exists():\n",
    "    with open(str(LINES_PATH), 'w') as fhand:\n",
    "        for path in JOB_PATHS:\n",
    "            df = pd.read_csv(path)\n",
    "            for line in parse_lines(df, \"text\"):\n",
    "                if not (line == \"\" or line.isspace()):\n",
    "                    fhand.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train Bigram Model\n",
    "To train a trigram model using Gensim, we must first train a bigram model, \"bigramize\" the text (by joining bigram phrases with \"\\_)\", then repeat the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Phrases class trains a phrase model The Phraser class is a wrapper that\n",
    "# cuts memory consumption of a phrase model by discarding state not needed for bigram detection\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "# Load in an iterator for lines of text saved to a file\n",
    "from gensim.models.word2vec import LineSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_PATH = DATA_PATH / \"models\"\n",
    "BIGRAM_MODEL_PATH = MODELS_PATH / \"bigram_model.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an iterator of the normalized texts\n",
    "unigram_sentences = LineSentence(str(LINES_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_phrase_model(text_iterator, output_path: Path):\n",
    "    \"\"\"\n",
    "    Train and save a phrase model. `text_iterator` should yield lists of tokens,\n",
    "    e.g. Gensim's LineSentence class\n",
    "\n",
    "    If a model has already been trained, load from disk.\n",
    "    \"\"\"\n",
    "    if not output_path.exists():\n",
    "        phrase_model = Phrases(text_iterator)\n",
    "        phrase_model.save(str(output_path))    \n",
    "        print(\"Phrase model saved to\", output_path)\n",
    "    else:\n",
    "        phrase_model = Phrases.load(str(output_path))\n",
    "        print(\"Loaded pre-trained phrase model from\", output_path)\n",
    "    return Phraser(phrase_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pre-trained phrase model from ../data/models/bigram_model.model\n"
     ]
    }
   ],
   "source": [
    "bigram_model = train_phrase_model(unigram_sentences, BIGRAM_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigram-ize the unigram texts and save to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIGRAM_LINES_PATH = CLEANED_PATH / 'bigram_lines.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved phrased lines to ../data/cleaned/bigram_lines.txt\n",
      "CPU times: user 425 ms, sys: 7.9 ms, total: 433 ms\n",
      "Wall time: 438 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def apply_phrase_model(line_iterator, phrase_model, output_path: Path):\n",
    "    \"\"\"Apply a phrase model to text and save to file\"\"\"    \n",
    "    if not output_path.exists():\n",
    "        with open(str(output_path), 'w') as fhand:\n",
    "            for sent in line_iterator:\n",
    "                phrase_line = ' '.join(phrase_model[sent])\n",
    "                fhand.write(phrase_line + '\\n')\n",
    "        print(\"Saved phrased lines to\", output_path)\n",
    "    else:\n",
    "        print(output_path, \"already exists\")\n",
    "\n",
    "apply_phrase_model(unigram_sentences, bigram_model, BIGRAM_LINES_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the resulting bigram-ed text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_sentences = LineSentence(str(BIGRAM_LINES_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. -pron- offer a unique domain to work within -pron- be a world_class provider of financial statistical_modelling couple with unbeatable employee condition and benefit\n",
      "\n",
      "2. -pron- be seek direct i.e. not via a recruiter application from talented developer who possess the desire and willingness to solve_problem of importance to business_outcome work well within -pron- team and have a dedicated and professional outlook on software_development process\n",
      "\n",
      "3. in_addition to be an excellent software developer -pron- will_also specialise have a desire to learn the follow area\n",
      "\n",
      "4. data_pipeline development\n",
      "\n",
      "5. a bachelor 's degree_in software_engineering computer_science or information system\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "import re\n",
    "\n",
    "# Look for some examples of bigrams\n",
    "def get_example_phrases(sentence_iterator, n_grams=2, num_examples=5):\n",
    "    \"\"\"\n",
    "    Takes an iterator of sentences as list of tokens and\n",
    "    prints some example that include phrases\n",
    "    \"\"\"\n",
    "    regex_pattern = \"_\"\n",
    "    for i in range(n_grams - 2):\n",
    "        regex_pattern += \"[a-z]*_\"\n",
    "\n",
    "    examples_found = 0\n",
    "    for tok_list in sentence_iterator:\n",
    "        sent = ' '.join(tok_list)\n",
    "        if re.search(regex_pattern, sent):\n",
    "            examples_found += 1\n",
    "            print(f\"{examples_found}. {sent}\\n\")\n",
    "        if examples_found >= num_examples:\n",
    "            break\n",
    "\n",
    "get_example_phrases(bigram_sentences, n_grams=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the Trigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIGRAM_MODEL_PATH = MODELS_PATH/ 'trigram_model.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pre-trained phrase model from ../data/models/trigram_model.model\n"
     ]
    }
   ],
   "source": [
    "trigram_model = train_phrase_model(bigram_sentences, TRIGRAM_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved phrased lines to ../data/cleaned/trigram_lines.txt\n"
     ]
    }
   ],
   "source": [
    "TRIGRAM_LINES_PATH = CLEANED_PATH / \"trigram_lines.txt\"\n",
    "\n",
    "apply_phrase_model(bigram_sentences, trigram_model, TRIGRAM_LINES_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_sentences = LineSentence(str(TRIGRAM_LINES_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. demonstrate outstanding verbal and write_communication_skill include the ability_to communicate effectively with technical and non_technical colleague\n",
      "\n",
      "2. high tertiary_qualification e.g. masters_or_phd\n",
      "\n",
      "3. -pron- will not consider visa sponsorship for_this_position and -pron- will not consider candidate who be locate overseas unless -pron- be return to australia within the next calendar month\n",
      "\n",
      "4. the application_form will include_these_question\n",
      "\n",
      "5. which of the follow_statement_best_describe -pron- right to work in_australia\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_example_phrases(trigram_sentences, n_grams=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
